{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a4a953-8b50-4f38-b7ae-0df86502886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_health_data(input_file_path, output_file_path, drop_cols_thresh=0.4):\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "#Def clean_health_data(input_file_path, output_file_path, drop_cols_thresh=0.4):\n",
    "#Load input data\n",
    "    data = pd.read_excel(input_file_path, sheet_name=1, engine='openpyxl')\n",
    "\n",
    "#Convert 'Y' and 'N' values to 1 and 0 respectively\n",
    "    data = data.replace({'Y': 1, 'N': 0})\n",
    "\n",
    "#Group rare values in 'Ntm_Speciality' column as 'OTHER' if the percentage of that category is less than 1%\n",
    "    ntm_spec_counts = data['Ntm_Speciality'].value_counts(normalize=True)\n",
    "    rare_ntm_spec = ntm_spec_counts[ntm_spec_counts < 0.01].index\n",
    "    data['Ntm_Speciality'] = data['Ntm_Speciality'].replace(rare_ntm_spec, 'OTHER')\n",
    "\n",
    "#Remove columns with missing value percentage above a threshold\n",
    "    data = data.dropna(thresh=int(data.shape[0] * (1 - drop_cols_thresh)), axis=1)\n",
    "\n",
    "#Replace 'Unknown' values in 'Tscore_Bucket_During_Rx' column with corresponding values from 'Tscore_Bucket_Prior_Ntm' column\n",
    "    data['Tscore_Bucket_During_Rx'] = np.where(data['Tscore_Bucket_During_Rx'] == 'Unknown', data['Tscore_Bucket_Prior_Ntm'], data['Tscore_Bucket_During_Rx'])\n",
    "\n",
    "#Convert '> -2.5' and '<= -2.5' values to 1 and 0 respectively\n",
    "    data = data.replace({'>-2.5': 1, '<=-2.5': 0})\n",
    "\n",
    "#Convert 'VLR_LR' and 'HR_VHR' values to 1 and 0 respectively\n",
    "    data = data.replace({'VLR_LR': 1, 'HR_VHR': 0})\n",
    "\n",
    "#Replace 'Unknown' and 'Other/Unknown' values with NaN\n",
    "    data = data.replace([\"Other/Unknown\", \"Unknown\"], np.nan)\n",
    "\n",
    "#Replace all missing values in each column with the mode of that column\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "    data = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "#Convert the 'Age_Bucket' column to numeric values based on the provided mapping\n",
    "    age_bucket_mapping = {'>75': 0, '65-75': 1, '55-65': 2, '<55': 3}\n",
    "    data['Age_Bucket'] = data['Age_Bucket'].map(age_bucket_mapping)\n",
    "\n",
    "#Detect and remove outliers using IQR\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[((data < lower_bound) | (data > upper_bound)).any(axis=1)]\n",
    "    data = data[~((data < lower_bound) | (data > upper_bound)).any(axis=1)]\n",
    "\n",
    "    # Export cleaned data to CSV file\n",
    "    data.to_csv(output_file_path, index=False)\n",
    "    \n",
    "clean_health_data(r'C:\\Users\\shrut\\Desktop\\Data Glacier Stuff\\Healthcare_dataset.xlsx', r'Clean_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c989684-c151-4233-ba98-014fe80c48ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def altCleaning(input_file_path):\n",
    "    \"\"\"\n",
    "    Perform data cleaning and pre-processing on an input Excel file.\n",
    "    \n",
    "    Args:\n",
    "    - input_file_path: str, path to the input Excel file\n",
    "    \n",
    "    Returns:\n",
    "    - tuple of numpy arrays:\n",
    "      - X: 2D array of shape (n_samples, n_features), pre-processed features\n",
    "      - Y: 1D array of shape (n_samples,), encoded target labels\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "#load the input data\n",
    "    data = pd.read_excel(input_file_path, sheet_name=1, engine='openpyxl')\n",
    "\n",
    "#Remove unnecessary columns\n",
    "    data = data.drop(columns=['Patient_ID', 'Persistency_Flag'])\n",
    "\n",
    "#Fill missing values with the most frequent value for each column\n",
    "    imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    features = imputer.fit_transform(data)\n",
    "\n",
    "#Encode the target variable as numeric labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    target = label_encoder.fit_transform(data.Persistency_Flag)\n",
    "\n",
    "#Encode the categorical features as binary vectors\n",
    "    ohe = OneHotEncoder()\n",
    "    features = ohe.fit_transform(features[:, :-1]).toarray()\n",
    "\n",
    "#Return the pre-processed features and the encoded labels\n",
    "    return features, target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
